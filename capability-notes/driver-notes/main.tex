\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathpartir}
\usepackage{tensor}
\usepackage{xspace}
\usepackage[dvipsnames]{xcolor}
\usepackage{iris}
\usepackage{marvosym}
\usepackage{xargs}
\usepackage{listings}

\setlength{\parskip}{0.3em}

\newcommand{\Z}{\mathbb{Z}}
\newcommand{\X}[1]{\ensuremath{\mathrm{#1}}}
\newcommand{\V}[1]{\ensuremath{\mathit{#1}}}
\newcommand{\I}[1]{\ensuremath{\mathtt{#1}}}
\newcommand{\Sf}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\T}[1]{\texttt{#1}}
\newcommand{\SL}{Separation Logic\xspace}
\newcommand{\pure}[1]{\tensor[^{\ulcorner}]{#1{}}{^{\urcorner}}} %Hacky {} to avoid double superscript

\newcommand{\FIXME}[1]{{\color{MidnightBlue} FIXME: #1}}

\newcommand{\MMIO}{\Sf{MMIO}\xspace}

\DeclareMathOperator{\initOKo}{init_{OK}}
\DeclareMathOperator{\initOKos}{init^{\X{sem}}_{OK}}
\newcommandx{\initOK}[3][2=r,3=m]{\initOKo(#1,#2,#3)}
\newcommandx{\initOKS}[4][2=r,3=m,4=W]{\initOKos(#1,#2,#3,#4)}
\DeclareMathOperator{\initBCo}{init_{BC}}
\DeclareMathOperator{\initBCos}{init^{\X{sem}}_{BC}}
\newcommandx{\initBC}[2][1=r,2=m]{\initBCo(#1,#2)}
\newcommandx{\initBCS}[3][1=r,2=m,3=W]{\initBCos(#1,#2,#3)}
\DeclareMathOperator{\driverC}{code}
\DeclareMathOperator{\trace}{tr}
\DeclareMathOperator{\lowval}{\Sf{lowval}}
\DeclareMathOperator{\lifto}{\Sf{lift}}
\newcommandx{\trInv}[2][1=P,2=\iota]{\operatorname{trInv}^{#2}(#1)}
\newcommand{\wrap}[1]{\operatorname{wrap}_{\mathrm{#1}}}
\newcommand{\bigast}[2]{\underset{#1}\Sep{\!\!\! #2}\;}
\newcommand{\app}{\mathbin{+\!\!+}}

\newenvironment{remark}
{ \bigskip\hrule\vspace{-1.3em}\nobreak
  \paragraph*{Remark:}}
{\vspace*{0.5em}\hrule\medskip}

\title{Capabilities, MMIO and Robust Safety}
\date{March 10, 2020}

\begin{document}

\maketitle

\section{Memory Mapped I/O: Operational Semantics}

The proposal is to simply represent read and writes to memory-mapped IO
addresses as events in a trace. This says nothing a priori about devices that
might be connected to these IO regions. In particular, without additional
assumptions, reading a byte from a memory-mapped region just returns an
arbitrary value.

If at some point we want to reason under the assumption that we are connected to
a specific device that reacts in a specific way, we can express that as an extra
\SL assertion, that we assume as a pre-condition, and that restricts the set of
different traces that we might observe.

\[
  \begin{array}{lcl}
    \X{EventTy} & := & \X{IOWrite} \; | \; \X{IORead} \\
    \X{Event} & := & \X{EventTy} \times \X{Addr} \times \Z \\
    \X{Trace} & := & \X{list} \; \X{Event} \\
    \X{State} & := & \underbrace{\X{Reg} \times \X{Mem}}_{\text{old state}}
                     \times \X{Trace} \\
  \end{array}
\]

Values of type \X{State} represent the state of a configuration in the
small-step operational semantics. In this setup, we assume the whole semantics
to be parameterized by the range of memory-mapped addresses: \MMIO.

\[
  \begin{array}{lcl}
    \MMIO & := & [\MMIO_{\X{b}}, \MMIO_{\X{e}}) \\
  \end{array}
\]

In the (current) operational semantics without MMIO, the operational semantics
of the \I{Load} instruction is:

\begin{mathpar}
  \inferrule[Load]
  { r[\X{src}] = (p,g,b,e,a) \\ \X{readAllowed}\; p \\ a \in [b,e) }
  { (r, m) \xrightarrow{\I{Load} \; \X{dst} \; \X{src}} (r[\X{dst} := m[a]], m) }
\end{mathpar}

With MMIO, we obtain two rules for \I{Load}:

\begin{mathpar}
  \inferrule[MemLoad]
  { r[\X{src}] = (p,g,b,e,a) \\ \X{readAllowed}\; p \\ a \in [b,e) \\ a \notin \MMIO}
  { (r, m, t) \xrightarrow{\I{Load} \; \X{dst} \; \X{src}}
    (r[\X{dst} := m[a]], m, t) }

  \inferrule[IOLoad]
  { r[\X{src}] = (p,g,b,e,a) \\ \X{readAllowed}\; p \\ a \in [b,e) \\ a \in \MMIO}
  { (r, m, t) \xrightarrow{\I{Load} \; \X{dst} \; \X{src}}
    (r[\X{dst} := x], m, t \app (\X{IORead}, a, x)) }
\end{mathpar}

Notice how in the second rule, we read an arbitrary integer $x$, and record it
in the trace.

The \I{Store} rule would be similar.

\newcommand{\stdin}{\X{in}}
\begin{remark}
As Lars remarked, the read rule introduces non-determinism into our operational
semantics.
This has lead to some complications in the past (the nature of which is still
mysterious to me; n.b. that we use\\ $\I{ wp\_lift\_atomic\_head\_step\_no\_fork}$
in our WP rules, and that one would allow non-determinism).
(one question I -Thomas- had in this respect; does the $\I{Alloc}$ rule in HeapLang
not introduce non-determinism in a similar way? Why is this not problematic?)
Lars' suggestion was to additionally parameterize the operational semantics by
an input-stream $\stdin$.
The updated \textsc{IOLoad} load rule might then look something like this:
\begin{mathpar}
  \inferrule[IOLoad]
  { r[\X{src}] = (p,g,b,e,a) \\ \X{readAllowed}\; p \\ a \in [b,e) \\ a \in \MMIO
  \\ n = \#\{i \mid t[i] = ( \X{IORead},\_\;,\_) \}  }
  { (r, m, t) \xrightarrow{\I{Load} \; \X{dst} \; \X{src}}
    (r[\X{dst} := \stdin[n]], m, t \app (\X{IORead}, a, \stdin[n])) }
\end{mathpar}

When parameterizing our development with multiple values, we could either write
them out as different Coq \texttt{Parameters} where we need them, or store them
as fields in our \texttt{DriverG} typeclass (the latter is the approach taken
in e.g.\ the code-base of ~\cite{sammler-2020}).
\end{remark}



We now have two options when it comes to modeling the memory $m$:
\begin{enumerate}
\item Include the \MMIO addresses into the map. Notice that, for any address in \MMIO, the specific value held by the map $m$ for
that address is now irrelevant. Indeed, $m$ is never read nor modified for
addresses in \MMIO (possible exception: see next remark). One could choose to enforce that a particular dummy value is stored in $m$ for these addresses. Instead, we choose to leave them
unconstrained.
\item Have $m$ model the physical RAM addresses only. This model is closer to
  the conceptual model of state that we wish to implement, since it does not
  require us to talk about the values in the heap that \MMIO locations are
  associated with. In case it is not harder to implement (which I currently do not think
  it is), it is to be preferred.
\end{enumerate}
Both approaches require us to make sure that no points-to chunks $l \mapsto \_$
with $l \in \MMIO$ can be created. In the next section, we assume the second
approach (until someone proves me wrong about it working).

\begin{remark}
  Additionally, we have the option of disallowing an execution
  with a \X{PC} register pointing to a $\MMIO$ location in the semantics.
  First off, consider that this is an edge case; since we always have points-to
  chunks describing the layout of code in memory (and a points-to chunk for
  location $l$ doubles as a proof that $l \not\in \MMIO$), it is trivial to prove that
  this case would not occur in any of our current examples.
  If we make no changes to the current code base, this behavior would be
  allowed, and the following would happen in both cases described above:
  \begin{enumerate}
  \item An unconstrained value is read from the location. Any instruction could
    be executed.
  \item The predicate $\I{MemLocate}$ in $\I{lang.v}$ will make sure
  that the default value $0$ is read and decoded into an instruction when we try
  to execute an \MMIO location.
  This would not cause a conflict with the current WP rules,
  since a points-to chunk is required in the precondition, ensuring that this
  case does not occur.
  Another alternative is to read the encoding of a $\X{NOP}$ instruction, instead of
  just the value $0$.
\end{enumerate}
  If we were to simply disallow execution when the PC points into \MMIO, we would make the semantics of all instructions slightly more complicated, but in a
  uniform way.
  We could simply add $a \not\in \MMIO$ to the predicate $\I{isCorrectPC}$ (or
  add it as an additional predicate), which is used to define failing execution.
  It would again not be a drastic change, since a points-to for the
  address $a$ the PC points to is required by the WP rules regardless, from which we
  can prove that $a \not\in \MMIO$.
\end{remark}

\begin{remark} With this presentation, the specification of the
``machine'' is very much decoupled from the model of the devices it might be
communicating with. This is a good thing, I think.

Nevertheless, one could consider an alternative presentation where the model of
the devices is more tightly integrated with the semantics of the machine. For
instance, one could make the operational semantics parameterized with the
devices' model, where each device is modeled as having some internal state, the
ability to react on reads or writes, or to perform an internal step. Then, the
operational semantics would either step the usual way, or whenever a device
steps.

I believe this would be somewhat similar to the semantics of I/O system calls
through a foreign function interfaces as formalized in
CakeML~\cite{cakeml-vstte17io}, and also in Perennial~\cite{perennial-lang}.
%


\end{remark}

\begin{remark} Alix says that the proposed style of operational semantics
(using a trace) is close to the semantics of \texttt{volatile} as in
CompCert---which is also how memory mapped addresses seem to be exposed to C
compilers in practice. So this is probably a good sign. 
\end{remark}


\section{\SL Resources}

We added a trace as part of the state, so we wish to also expose it as a \SL
assertion. Recall the current definition of the state interpretation:
\[
  \X{state\_interp} \; (r,m) := \X{gen\_heap\_ctx}\; r \ast \X{gen\_heap\_ctx}\; m
\]


\newcommand{\tracefull}[1]{\ownGhost{\gamma_{\X{T}}}{\authfull{#1}}}
\newcommand{\tracefrag}[1]{\ownGhost{\gamma_{\X{T}}}{\authfrag{#1}}}

The simplest way to account for the trace is to directly expose it in a
monolithic fashion. In that case, the state interpretation additionally holds a
resource for the trace:

\begin{align*}
    \X{state\_interp} \; (r,m,t) :=& \X{gen\_heap\_ctx}\; r \ast\\
    &\X{gen\_heap\_ctx}\; m \ast \dom(m) \cap \MMIO = \emptyset \ast
    {\color{BrickRed}\tracefull{t}}
\end{align*}

\begin{remark}
For the case where the \MMIO locations are still part of the heap $m$, this
would look as follows:
\[
  \X{state\_interp} \; (r,m,t) :=
    \X{gen\_heap\_ctx}\; r \ast
    \X{gen\_heap\_ctx}\; (m \setminus \MMIO) \ast
    {\color{BrickRed}\tracefull{t}}
\]

Sanity check: we never have allocation of new locations $l$ in our capability machine, but if we
did, that would work in both settings by requiring that $l \not\in \MMIO$ in the
operational semantics rule for \textsc{Alloc}.
\end{remark}

Note that we restrict the usual ``points-to'' assertions to be used only for
non-MMIO addresses. Instead, to assert ownership of the MMIO region, the user
works with assertions of the form $\tracefrag{t'}$. Such an assertion is not
duplicable, and grants full ownership over the trace. In particular, it allows
one to \emph{update} the trace by emitting events, i.e. by performing I/O
operations.

The wp-rules for \I{Load} and \I{Store} need to be updated consequently. For
instance, the rule for a \I{Load} reading the integer $x$ on a MMIO address $a$
now requires $\tracefrag{t}$ in the pre-condition (for some $t$), and provides
$\tracefrag{t \app (\X{IORead}, a, x)}$ in the post-condition.

The corresponding resource algebra is $\authm(\exm(\X{Trace}))$. A few relevant
rules are:

\[
  \begin{array}{l}
    \tracefull{t} \ast \tracefrag{t'} \wand \pure{t = t'} \\
    \tracefrag{t} \ast \tracefrag{t'} \wand \FALSE \\
    \tracefull{t} \ast \tracefrag{t} \vsW \tracefull{t'} \ast \tracefrag{t'} \\
  \end{array}
\]


\begin{remark} This is very coarse-grained: either one has the full
ownership for performing I/O and reasoning about it, or one cannot know anything
about it.

A first extension could be to allow observing prefixes of the trace (since
events can only be appended to the trace). The observation that the trace
has a given prefix would be duplicable. This again seems to be an application of
monotonicity, that could be realized by having a duplicable AtLeast part as part
of $\tracefrag{t'}$,
similarly to how we currently model Monotone References.

Another extension, that seems very useful for modular reasoning, would be to
allow splitting the trace along separate range of addresses. Concretely, a trace
containing events about the range of MMIO addresses $[a,c)$ could be split into
two traces, granting ownership over events on addresses $[a,b)$ and $[b,c)$
respectively. Note that recombining these two traces would only yield some
unspecified interleaving of the events from the two traces, and not necessarily
yield the original trace, since in our model, we cannot know the exact interleaving of IO operations issued by different parties.

One application of this second extension could be the verification of an example
involving ``multiplexed'' I/O, where two separate parts of the code are granted
separate ownership over separate MMIO addresses. These two separate pieces of
code would be verified separately; then, in the end, one could prove that one
gets \emph{some} interleaving of all the events emitted by both components.
\end{remark}

\newcommand{\MMIOag}{\ownGhost{\gamma_{\X{MMIO}}}{\authfull (\X{MMIO})}}

\begin{remark}
  As an alternative to having the set of MMIO addresses (\MMIO) as a global
  parameter, we might want to make it part of the state in the operational
  semantics. In that case, we would need another resource algebra to model the
  MMIO locations, i.e. add do the state interpretation we had before:
%
\[
  \X{state\_interp} \; (r,m,t,\MMIO) := \ldots \ast \MMIOag
\]

(where $\authm(\exm(\X{Trace}))$ is the resource algebra).
\end{remark}

\begin{remark}
In the future, we might be interested in the dynamic allocation of MMIO memory.
The question is what this would mean, though, since the set of available devices
allowing for MMIO access and the concrete buffers they provide will most likely
still be modeled as fixed at runtime.
Rather, this would allow us to take (un)mapped MMIO locations, connected to the different devices, and (un)map them anywhere in main memory.
This would require a different way of modeling MMIO, where we need both a notion
of the total pool of possible MMIO locations, and a description of the currently
mapped locations. We could model this using an authoritative RA.
\end{remark}

\section{Toplevel Theorem (\emph{à la} OCPL)}

Let us start with a brief recap of the toplevel ``Robust Safety'' theorem for
OCPL itself (and its key ingredients), then the extension (by Thomas) of OCPL to
include a \I{print} capability, and finally move to the capability machine
setting.

\subsection{OCPL}

The {\sc RobustSafety} theorem of OCPL is as follows:

\begin{mathpar}
  \mprset{vskip=0.3em}
  \inferrule
  {C \in \textit{AdvCtx} \\
    e \; \X{closed} \\
    \hoare{\TRUE}{e}{x\ldotp \lowval x} \\
    (C[e]);(\emptyset, \Sf{OK}) \longrightarrow^* T';(h',g')
  }
  {g' = \Sf{OK}}
\end{mathpar}

For any closed expression $e$, if $e$ has been verified to only return low
values, then running $e$ wrapped in an adversarial context $C$ from an initial
state, then we can observe that every reachable state is good
($g' = \Sf{OK}$ means that no assertion has failed in $e$).

$C \in AdvCtx$ means that $C$ cannot contain assertions (otherwise one could
trivially contradict the theorem by taking
$C[\cdot] = \Sf{assert}\spac \X{false}$), and cannot contain references to raw
memory locations (otherwise one could directly access $e$'s private state,
invalidating the local state encapsulation mechanisms).

\newcommand{\lift}[2]{\lifto #1 \: #2}
\newcommand{\liftP}[1]{\lift{\Psi}{#1}}

$\Sf{lowval}\; x$ intuitively means that $x$ cannot be used to directly
access private (or ``high'') locations. It is formally defined using a logical
relation ``$\liftP{v}$'', which more generally asserts that the value $v$ only
gives direct access to locations that satisfy the predicate $\Psi$.

\[
  \begin{array}{lcl}
    \liftP (\Sf{rec}\; f\; x.\; e) & \eqdef
    & \later \forall v.\; \hoare{\liftP{v}}{e[v/x,\Sf{rec}\;f\;x.\; e/f]}{y.\; \liftP y} \\
    %
    \liftP (v_{1}, v_{2}) & \eqdef & \later (\liftP v_{1}, \liftP v_{2}) \\
    %
    \color{BrickRed} \liftP \ell & \color{BrickRed} \eqdef & \color{BrickRed} \Psi \; \ell \\
    %
    \ldots
  \end{array}
\]

Then, $\lowval x$ is defined as $\lift{\Sf{lowloc}}{x}$, where
$\Sf{lowloc}$ is a predicate characterizing the region of memory containing
``low locations'' (distinct from the other region containing ``high
locations'').

\subsection{OCPL with \I{print}}

\newcommand{\OutV}{\Sf{Out}}

In Thomas' extension of OCPL, a new value $\OutV$ is added, denoting an
``output object capability'', as well as a $\Sf{print}$ primitive, where
$\Sf{print}\; \OutV\; v$ effectively ``prints'' the value $v$, i.e. adds it
to the trace of printed values.

One then wants to be able to encapsulate the use of $\OutV$, for instance by
defining object capabilities that enforce some invariants on the values being
printed. In that setting, $\OutV$ is considered as a ``high'' value:
%
\[
  \begin{array}{lcl}
    \liftP \OutV & \eqdef & \FALSE
  \end{array}
\]

The theorem then becomes:
%
\begin{mathpar}
  \mprset{vskip=0.4em}
  \inferrule
  {C \in \textit{AdvCtx} \\
    e \; \X{closed} \\
    \trInv \vdash \hoare{\TRUE}{e}{x.\; \operatorname{\Sf{lowval}} x} \\
    (C[e]);(\emptyset, \Sf{OK}); \emptyset \longrightarrow^* T';(h',g'); t
  }
  {g' = \Sf{OK} \wedge P(t)}
\end{mathpar}
, where we introduced the following notation:
%
\[
  \begin{array}{lcl}
    \trace(t) & \eqdef & \tracefrag{t}\\
    \trInv & \eqdef & \knowInv{\iota}{\exists t.\; \trace(t) \ast \pure{\! P(t)}}
  \end{array}
\]


That is, if $e$ has been verified under the assumption that the predicate $P$
holds as a trace invariant, then executing $e$ in an adversarial context yields
a trace that does satisfy $P$.

$C \in \textit{AdvCtx}$ also has to be extended to forbid $C$ from containing
$\OutV$.

\medskip

To be slightly more general, we could actually allow sharing $\OutV$ in case the
predicate $P$ does not place any constraints on the output, i.e. it is the
$\TRUE$ predicate. Technically, we could hence have the following alternative
definition for $\Sf{lift}$ (although admittedly, it does look a bit
hard-coded):
%
\[
  \begin{array}{lcl}
    \liftP \OutV & \eqdef & \trInv[\Lam{\_}.\TRUE]
  \end{array}
\]

\subsection{Capability Machine with MMIO}

\subsubsection{Logical relation}

\newcommand{\VR}{\mathcal{V}}
\newcommand{\ER}{\mathcal{E}}
\newcommand{\RR}{\mathcal{R}}
\newcommand{\notMMIO}{\overline{\MMIO}}

Similarly to $\Sf{lift}$, we can generalize the existing logical relation
to thread a constraint on directly accessible memory locations. One would
parameterize the value, expression and register relations ($\VR$, $\ER$ and $\RR$)
with a predicate $\Psi$ on addresses.

Then, for any permission $p$ that includes either the R or W bit, $\VR$
is extended as follows:

\[
  \VR^{\Psi}(W)(p, g, b, e, a) \eqdef \underbrace{\ldots}_{\text{as before}} \ast \; \pure{\forall a' \in [b,e).\; \Psi(a')}
\]

Then, $\ER^{\Psi}$ and $\RR^{\Psi}$ are simplify defined by threading the extra
$\Psi$ parameter through the existing definition.

Finally, for our relation to characterize ``low values'' that do not give direct
access to MMIO addresses, one would instantiate $\Psi$ with a predicate
$\notMMIO$ that excludes memory mapped addresses:

\[
  \notMMIO(a) \eqdef a \notin \MMIO
\]

Then, $\VR^{\notMMIO}$ is similar to the $\lowval$ predicate of OCPL.
Intuitively, a value in the relation does not directly point to memory-mapped
locations, nor can it gain access to memory-mapped locations indirectly,
similarly to how $\lowval$s cannot grant access to high locations
directly. The relation $\ER^{\notMMIO}$ specifies that, if we fill the registers
with values in $\VR^{\notMMIO}$, then the invariants in a private future world
of our starting world will be satisfied at the end of execution.

\begin{remark} As it is defined above, the ``generalized'' value relation
is in fact not very useful for instantiation of $\Psi$ other than $\notMMIO$.
Indeed, even if $\Psi$ \emph{does} allow referring to addresses in the $\MMIO$
region, the value relation does not grant any corresponding resources. The fix
would be to use the generalized trace resources mentioned previously, and grant
ownership for the part of the trace corresponding to the addresses in
$[b,e) \cap \MMIO_{\X{pub}}$ with $\MMIO_{\X{pub}}$ the shareable subset of
addresses in \MMIO.
\end{remark}


\subsubsection{Robust safety theorem}

A first attempt at adapting the OCPL robust safety theorem to the capability
machine setting might look something like the following
{\color{BrickRed}\textbf{(incomplete!)}} statement.

\newcommand{\Wpub}{\sqsupseteq^{\X{pub}}}
\newcommand{\Wpriv}{\sqsupseteq^{\X{priv}}}
\begin{mathpar}
  \mprset{vskip=0.5em}
  \inferrule
  { \forall a_{i} \in A_{\X{entry}} \ldotp\,
      \knowInv{\iota}{\exists t.\; \tracefrag{t} \ast P(t)}\!
         \vdash
         \forall W \ldotp\;\ER^{\notMMIO} (W) (\X{RX}, g, b, e, a_i)
       \\
     \\
    (r[\overline{r_{a_{i}} := (\X{E}, g, b, e, a_i)}], m, \emptyset) \longrightarrow^*
    (r', m', t)
  }
  {P(t)}
\end{mathpar}

The code that is verified (similar to the expression $e$ in OCPL) is here given
as a set of \emph{entrypoints} (addresses) $A_{\X{entry}}$.
%
The capability $(\X{RX}, g, b, e, a_i)$ then points to the $i$th entry point of
the code we want to gradually verify.

The capability $(\X{E}, g, b, e, a_i)$ then represents a closure for this same piece
of code. Adversarial code only gets access to the closure (as an enter
capability), in order to avoid them from executing or reading arbitrary lines of
code within the trusted module.

Notice the universal quantification over worlds in the precondition;
this needs to be there, since we do not know in what world our code will be
called.

\begin{remark}
  We could simplify the theorem statement by only considering the case of a
  single entrypoint. This is equivalent: a piece of code that wants to expose
  two distinct ``methods'' can implement a single toplevel entrypoint that
  immediately returns two pointers that can then be used to invoke the two
  methods.
  %
  This would make the toplevel theorem simpler, at the cost of somewhat more
  contrieved calling convention between trusted and untrusted code.
  Another alternative is to provide an opcode to specify the operation that
  needs to be performed.
  This is slightly less general, since it does not allow providing read access
  only to an adversary.
\end{remark}

\begin{remark}
The universal quantification on worlds was not explicitly present in the OCPL
formalization.
The reason for that is that (I think so at least, do not quote me
on this - Thomas) they
used the built-in Iris worlds within their definition of weakest precondition,
by leveraging the state interpretation, which is universally quantified over in
the definition of weakest precondition.
As we discussed before, if we do away
with local capabilities, it should be possible to fall back onto Iris' notion of
worlds, which would allow us to remove the universal quantification in the
above definition too because it would be implicitly present in the WP inside $\ER$.

It would be interesting to have a discussion about how to do away with the
worlds if we remove local capabilities, regardless of whether we will in the
end, since that might shed some light on why the worlds look the way they do
right now.
\end{remark}

\begin{remark}
  Note that we could have written
  $\ldots \vdash \forall W \ldotp \; \VR^{\notMMIO} (W) (\X{E}, \ldots)$
  in the above theorem, instead of using the expression relation. This is
  equivalent, and easily unfolds to the former statement through the definition
  of the value relation. I wrote $\ER$ to place the focus on the execution of
  the driver being safe. I consider this a matter of taste.
\end{remark}

\medskip

The theorem above is \emph{incomplete}. In other words, it is not provable as
is, because it includes no notion of adversarial context (similar to OCPL's
\textit{AdvCtx}), and therefore imposes no restriction on the adversarial code
(i.e., the contents of the $r$ and $m$ other than our verified code).
%
As such, the statement can be trivially falsified by taking an attacker with
direct read or write access to any location in \MMIO, or with direct access to
the trusted code's internal state.

We move to a theorem statement that correctly constrains the adversary in two
steps:
%
\begin{enumerate}
  \item We add a syntactic condition (on the state of memory and registers) to
    the tentative statement of our robust safety theorem, ensuring that the
    adversary code cannot gain access to any non-$\X{E}$ capabilities pointing into
    the driver code or any capabilities pointing into $\MMIO$ directly.
    Alternatively, we can formulate this condition in a semantic way, see below.
    Additionally, we specify what exact code the driver contains, so that we can
    use this in our proof that the driver is secure. This will involve adding an
    invariant to the robust safety theorem.
%
  \item Then, we provide an end-to-end statement that assumes the existence of a
    piece of boot code, that gets to run first when the capability machine
    starts up, and makes sure the above condition indeed holds before passing
    control to the adversary.

    The boot code is part of the trusted code base, and must satisfy a given
    specification, as a precondition of the toplevel theorem.

    The particular implementation of the boot code depends on the model of the
    initial state of the machine. If the memory can contain any capability at
    startup, then the boot code has to erase the memory before passing control.
    If we assume that the initial memory cannot contain any capabilities
    whatsoever, then the boot code does not need to do any cleanup.
\end{enumerate}

In this setting, we can subdivide the memory $m$ into 3 relevant subsections;
$m = m_{\MMIO} \uplus m_{\X{driver}} \uplus m_{\X{adv}}$ %\uplus m_{\X{frame}}
with the following meaning:
\begin{itemize}
\item $m_{\MMIO}$ contains the memory-mapped locations
\item $m_{\X{driver}}$ contains the driver code
\item  $m_{\X{adv}}$ contains the adversary's code and data (this will also
  include the boot code in the general setting, since it does not contain any
  inherently dangerous capabilities itself).
\end{itemize}

\newcommand{\nonCap}[1]{\ensuremath{\mathrm{nonCap}(#1)}}

We can then implement the syntactic check as requiring registers and memory to
only contain non-capability values:

\def \MathparLineskip {\lineskiplimit=0.7em\lineskip=0.7em}
\begin{mathpar}
  \nonCap{\X{inl}\; z} \eqdef \TRUE \and
  \nonCap{\X{inr}\; (p,g,b,e,a)} \eqdef \FALSE \and
  \nonCap{\V{reg}} \eqdef \forall r \in \dom(\V{reg}).\; \nonCap{\V{reg}(r)} \and
  \nonCap{\V{mem}} \eqdef \forall l \in \dom(\V{mem}).\; \nonCap{\V{mem}(l)}
\end{mathpar}

\newcommand{\notMapsToR}[2]{\rightarrow^{\overline{#1}}\!\!(#2)}
\newcommand{\Winit}{\X{W_{init}}}
\newcommand{\Wemp}{\emptyset}

Given this definition, we can now formalize the initialization constraints on
registers $r$ and memory $m$, given the region \MMIO and
the driver's address space $[b,e)$ as follows (for a resource-aware formulation;
see the bootSpec postcondition below):

\begin{mathpar}
  \mprset{vskip=0.4em}
  \inferrule
  { m = m_{\MMIO} \uplus m_{\X{driver}} \uplus m_{\X{adv}}\\
    \dom( m_{\MMIO} ) = \MMIO \\
    \dom( m_{\X{driver}} ) = [b,e)\\
    \dom( m_{\X{adv}} ) = [b_{\X{adv}},e_{\X{adv}})\\
    \nonCap{\V{r}}\\
    \nonCap{\V{m_{\X{adv}}}} \\
    r[\X{PC}] = (\X{RWX}, \X{G},b_{\X{adv}},e_{\X{adv}},b_{\X{adv}})\\
  }
  {\initOK{[b,e)}}
\end{mathpar}

It should be noted that a more general, semantic version of this specification
is also possible. It would contain the following elements, that should all
follow directly from the specification above (TODO: write this out properly and
do the same for the semantic bootspec):
\begin{itemize}
\item All registers except \X{PC} are in the value relation with respect to
  either the empty world $\Wemp$ (if we do not want to allow any non-empty, non-enter
  capabilities in registers), or a world $\Winit$ containing a single standard region for
  all of the adversary's memory.
  The \X{PC} register satisfies both the read- and write conditions (note the
  parallel with the fundamental theorem) with respect to this same world, if we
  picked the non-empty world, or just points to the adversary's memory, which
  does not contain capabilities (if we
  picked the empty world, a capability pointing into memory can never be valid).
  It feels slightly less artificial to pick the non-empty world option here.
\item We have possession of the predicates $\I{region}$ and
  $\I{sts\_full\_world}$ for the world we picked in the previous bullet. we will
  need these to apply the fundamental theorem.
\item A description of the exact driver code, still in terms of points-to chunks
  (or, in this case equivalently, an invariant). We can write this invariant as
      $\driverC(b,e,\overline{\V{op}_l}) = \knowInv{\iota}{\bigast{l \in [b,e)}{l \mapsto_{a} \mathit{\V{w}_l}}}$, with $\V{w}_l$
      some hard-coded driver word (an instruction or a capability) at location $l$.
\end{itemize}


and subsequently formulate the robust safety theorem as follows (using the
semantic specification for $\initOKo$, which references the initial world):

\begin{mathpar}
  \mprset{vskip=0.5em}
  \inferrule
  { \forall a_{i} \in A_{\X{entry}} \ldotp\,\left\{
    {\begin{array}{ll}
    \knowInv{\iota}{\exists t.\; \tracefrag{t} \ast P(t)}\ast
    \driverC(b,e,\overline{\V{w}_l})\!
         \vdash \\
         \forall W \Wpriv \Winit \ldotp\;\ER^{\notMMIO} (W) (\X{RX}, g, b, e, a_i)
        \end{array}} \right. \\
   \initOKS{[b,e)}[r][m][\Winit] \\
  (r[\overline{r_{a_{i}} := (\X{E}, g, b, e, a_i)}], m, \emptyset) \longrightarrow^* (r', m', t)\\
  }
  {P(t)}
\end{mathpar}

where we have set the PC up to be a sensible capability (pointing to
$b_{\X{adv}}$ without loss of generality).

Notice how the syntactic check for the registers is only performed on the set of
registers $r$, allowing the closures in $\overline{r_{a_i}}$ to point into to
the driver address space (TODO: we should change this though and add a
requirement to $\initOKo$).
(TODO: introduce notation for trace-owndership and predicate P holding)

\begin{remark}
  If useful, the syntactic check can be relaxed to allow any capabilities that
  do not point into the MMIO region or the driver's memory. One would define the
  predicate $\notMapsToR{R}{w}$, that takes a word, memory region or register
  file and checks if it points into the forbidden region $R$ as follows:

\[
  \begin{array}{lcl}
    \notMapsToR{R}{\X{inl}\spac z} & \eqdef
    & \TRUE \\
    %
    \notMapsToR{R}{\X{inr}\spac (p,g,b,e,a)} & \eqdef & R \cap [b,e)\; =
                                                 \emptyset  \\
    %
    \notMapsToR{R}{\V{reg}} & \eqdef & \forall r \in \dom(\V{reg}) \ldotp\spac \notMapsToR{R}{\V{reg}(r)} \\
    %
    \notMapsToR{R}{\V{mem}} & \eqdef & \forall l \in \dom(\V{mem}) \ldotp\spac   \notMapsToR{R}{\V{mem}(l)}
  \end{array}
\]

Then, one would use $\notMapsToR{\MMIO \cup [b,e)}$ in place of $\nonCap{}$.
\end{remark}

Having this theorem in our toolbox, we can now take a closer look at scenario 2
above, where a piece of boot code is used to set the memory up correctly,
obviating the need for any other assumptions than that the boot code behaves
according to some spec. Concretely, we want the boot code to uphold a spec that
allows us to prove the above theorem.
%
(Alternatively, we could also just implement one specific instance of boot code,
and prove that after it finishes executing, all preconditions to apply the above
theorem are met.)

Let $r_0$ and $m_0$ be the respective initial state of registers and memory
immediately after booting. We assume that the following two properties hold,
where $l_\X{boot}$ is some memory location (initially loaded in PC):
%
\begin{mathpar}
  \dom(m_0) = [0,\X{MEM_{MAX}}) \and
  r_0[\X{PC}] = (\X{RWX}, \X{G},0,\X{MEM_{MAX}},l_{\X{boot}})
\end{mathpar}

Depending on the specifics of the operiational semantics, we might have more
information about $m_0$ and $r_0$, that can then be used in the implementation
of the boot code (e.g., $m_0$ might be initialized to only zeroes).

We also assume the capability machine to initially start execution in the boot code  at address $l_{\X{boot}}$.
%
Then, the syntactic specification for the boot code that we have to prove is stated as follows:


\[
  \begin{array}{l}
  \X{bootSpec}(P, g, b, e, A_{\X{entry}}) \eqdef {} \\[0.8em]
    \quad
  \begin{array}{l}
    \left\{
    \begin{array}{l}
      \X{PC} \mapsto_{r} (\X{RWX}, \X{G}, 0, \X{MEM_{MAX}}, l_{\X{boot}}) \ast {} \\[0.5em]
      \bigast{r \in \X{Reg} \setminus \X{PC}}{r \mapsto_{r} r_{0}[r]}
      \ast \bigast{m \in \X{Mem} \setminus \MMIO}{m \mapsto_{a} m_{0}[m]}
      \ast \; \tracefrag{\emptyset}
    \end{array}
    \right\}
    \\[2em]
    \quad \I{Seq}\; (\I{Instr}\; \I{Executable})
    \\[0.5em]
    \left\{
    \begin{array}{l}
      \exists b_{adv}\; e_{adv}\; t.\; \\[0.5em]
      \quad
      \begin{array}{l}
        \X{PC} \mapsto_{r} (\X{RWX}, \X{G}, b_{adv}, e_{adv}, b_{adv}) \ast {} \\[0.7em]
        \bigast{a_{i} \in A_{\X{entry}}}{r_{a_{i}} \mapsto_{r} (\X{E},g,b,e,a_i)} \ast
        \bigast{r \in Reg\setminus \{\X{PC}, A_{\X{entry}}\}}{r \mapsto_{r} \X{inl}\; \_} \ast {} \\[1.4em]
        \bigast{m \in [b_{adv}, e_{adv})}{m \mapsto_{a} \X{inl}\; \_} \ast
        \bigast{m \in [b, e)}{m \mapsto_{a} \_} \ast
        \; \tracefrag{t} \ast \pure{P(t)}
      \end{array}
    \end{array}
    \right\}
  \end{array}
  \end{array}
\]

\begin{remark}
As Frank mentioned, if we do not enforce any validity constraints on the part of the adversary's memory that is not reachable
from the valid registers themselves, the driver cannot read from this memory in
a useful way during execution (since the memory might contain any value whatsoever).
There is currently no concrete use case for this scenario yet, so we left such
condition on the adversary's memory out, but it is good to be aware of.
\end{remark}

Intuitively, establishing this specification ensures that, after running the
boot code, we arrive in a state that satisfies $\initOKo$.


The resulting boot-code formulation of the robust safety theorem is now a


\begin{mathpar}
  \mprset{vskip=0.5em}
  \inferrule
  {  \forall a_{i} \in A_{\X{entry}} \ldotp\,\left\{
    {\begin{array}{ll}
    \knowInv{\iota}{\exists t.\; \tracefrag{t} \ast P(t)}\ast
    \driverC(b,e,\overline{\V{op}_l})\!
         \vdash \\
         \forall W \Wpriv \Winit \ldotp\;\ER^{\notMMIO} (W) (\X{RX}, g, b, e, a_i)
        \end{array}} \right. \\   \X{bootSpec}^{\X{sem}}(P,g,b,e,A_{\X{entry}}, \Winit) \\
  (r_0, m_0, \emptyset) \longrightarrow^* (r, m, t)\\
  }
  {P(t)}
\end{mathpar}

Note that to link scenario 2 to scenario 1, we need a slightly adapted version
of the robust safety theorem stated previously, where the initial trace is
allowed to not be empty, but rather just satisfy $P(t)$, but that should not
cause any problems.

Note as well that if the boot-code performs I/O, then it is required to preserve
the invariant $P$ on the trace. If needed, one could come up with a more general
theorem statement, where the boot code is allowed to perform arbitrary I/O, and
where $P$ is thus only true of the suffix of the trace for events that occur
\emph{after} the boot code has run...

\begin{remark}
  On the level of the operational semantics, proving the boot specification
  corresponds to proving that the following holds, in order to use our concrete
  driver implementation with the robust safety theorem above (the driver still
  needs to be proven safe separately):
\[
  \begin{array}{l}
    (\textsc {BootCodeOK}) \\[0.5em]
%
    \exists n\; b\; e\ldotp (r_0, m_0, \emptyset) \longrightarrow^n (r'[\overline{r_{a_{i}}
    := (\X{E}, g, b, e, a_i)}], m', t) \\[0.5em]
    {} \land P(t) \land \initOK{[b,e)}[r'][m']
  \end{array}
\]
\end{remark}
\begin{remark}
 Dominique made the remark that we might want to allow capabilities pointing
 into the driver code that are not enter capabilities, but can just generally be
 proven safe wrt.\ the driver code. This scenario (which we currently do not
 support out of simplicity considerations) would force us to add the driver code
 as a static region to the world. While this would work on paper, it does not in the
 current Coq formalization, since all regions that standard regions point to are
 forced to be standard as well (through the conditions in the different cases of
 the $\I{interp1}$ predicate). Essentially, this behavior is disallowed because
 the Coq development merged the notion of read- and write condition, and there
 is hence no room to define a static region which defines a stricter reading
 policy, but hence disallowes writing. More generally, it is currently
 impossible to plug non-standard regions into the world, and allow standard
 regions to depend on them in any way whatsoever. This was not a problem up
 until now, since our examples never required this sort of dependency.
\end{remark}
\subsubsection{Concrete boot and driver code}
\label{subsec:driverimpl}
Now we have a closer look at the concrete example we would like to verify,
including what its boot code looks like. Our goal is to prove that this concrete
example satisfies \X{bootSpec} (alternatively, \textsc{BootCodeOk}) and this
last robust safety theorem.

The code for for the driver scenario we want to gradually verify can
be found in \T{driver\_code.v}. This example file contains more details on the
scenario in the comments. From a more high-level perspective, it contains a
trusted part, consisting of a single MMIO location, boot code to properly set up
the capability machine at start-up, and the code for the driver itself. On the
other hand, the example also contains an untrusted part, consisting of a known,
but untrusted code section and sandbox section (which we do not make assumptions
over).
The first address of the adversary code section is what the trusted part jumps
to once it has finished setting up.

The boot code is where execution starts off when the capability machine is
powered on.
It contains an omnipotent RWX capability (i.e. ranging over all of memory and
providing full permissions over it) starts off execution.
(\textbf{Design Alternative:} in the long run, it might be worthwhile to provide
the boot code with a RWLX capability. Since RWX cannot be upgraded to RWLX, it
is impossible in the current setting to develop a secure stack calling
convention \'a la Lau, where the stack capability has to be local-WL and (in this
case) the driver code has to ensure that there is no other WL than the stack.
However, having a global stack capability is currently not an issue, since the interface to our driver is first order, i.e. it will
never create another adversary stack frame on top of itself (currently, it does
not even use the stack in the first place!), and since we are working in a
single-threaded setting (not very relevant, but I think the multi-threaded
setting is an interesting thought experiment). I avoided unnecessary
complications and hence kept the omnipotent capability as RWX. If the omnipotent
capability were to become RWLX in the future, we would have to be careful using
a stack, since if we want our secure calling convention with a higher order
interface to our driver API, there cannot be any adversary-accessible global
write-local memory, i.e. the reduced omnipotent capability cannot be allowed to be global if we pass it to the adversary. We would thus have to pass a stack capability that we explicitly make local, and a global RWX capability for the rest of memory)

The boot code has the following responsibilities:
\begin{itemize}
  \item Generate the necessary closures (i.e. Enter capabilities) for the
    driver's read and write methods, so that the adversary can use safely use
    them to perform I/O, and any properties that the driver wants to uphold on
    the input-output stream can actually be enforced.
%
  \item Wipe all of the adversary's sandbox section, to make sure no remaining
  capabilities can be found there.
  %
    (\textbf{Design Alternative:} maybe we should try to find out how CHERI
    handles this; is it possible that any lingering capabilities are left in RAM
    on machine start-up? In any case, we are already being slightly unrealistic
    by assuming the adversary code section is just \emph{there}. We have the
    option to not do any erasure, and just make the assumption that adversary
    memory contains no capabilities pointing into MMIO or pointing into the
    driver.).
  %
    It does not, however, wipe the untrusted, hard-coded adversary routine that
    reads $N$ lines of code from a single (and the only) MMIO location in
    memory.
%
  \item Reduce the omnipotent capability to provide RWX access to all of the
    adversary's code, makes it point to the first element of the adversary's
    code section and jumps to it, in order to hand control to the adversary.
    Before the jump, it clears all registers except for the 2 containing the
    read and write driver closures, in order to make sure that no extra
    permissions leak to the adversary.
\end{itemize}

\section{Potential driver clients/properties}
The concrete driver that we described in Section~\ref{subsec:driverimpl} does
not yet enforce any useful safety properties on the traces that it outputs. This
section describes a couple such properties that we might want to enforce,
modifications to the driver that they require and example clients that make use
of our modified driver.

\subsection{Stateless properties}

\paragraph{Printing values $\le 1000$}

To only print values $\le 1000$, we need to wrap the driver's read method in a
function that checks this condition, before passing control to the actual read
method.
On an abstract level, given a function $f$, we would have the following wrapper:
\[
  \wrap{\le 1000} f \eqdef \lambda x\ldotp \X{assert}(x \le 1000); f\; x
\]
, and the closure we share with the environment is hence $\wrap{\le
  1000}(\X{read})$ instead of just $\X{read}$.

A trivial misbehaving client could look as follows:
(TODO: ask Dominique for Lau's code on environments)
\begin{lstlisting}
  move r1 1001
  jmp r2
\end{lstlisting}
It simply loads an argument to write and jumps to the write routine.

A well-behaved client might look as follows:
\begin{lstlisting}
  move r1 0
  jmp r2
\end{lstlisting}

\paragraph{Modelling channel-specific safety properties}
Here, we could encode different channels into our integers (in the spirit of
what Frank mentioned), and enforce different safety properties on the different
channels (by ensuring that we can split $P$).
On a conceptual level, this does not require any changes whatsoever.

\subsection{Stateful properties}

\paragraph{Performing $\le 1000$ I/O operations}

To ensure that no more than 1000 values will be read or sent, the driver needs to
keep some internal state, e.g.\ a single integer value $n$ (at location $l_n$) representing the number of times it has been called.

To accommodate this local state, the initial world will need to contain one
extra region for location $l_n$, that allows any integer values $\ge 0$. Since
this region only has a single state, we can again short-circuit the world and
enforce the constraints we want on $n$ through an invariant directly. We now
discuss the concrete constraint that we are looking for.

We have to tie this integer $n$ to the number of I/O events
present in the trace $t$, otherwise it will prove impossible to verify our
driver. Concretely, the invariant we will verify our driver under changes from
$\knowInv{\iota}{\exists t\ldotp \tracefrag{t} \ast \pure{|t| \le 1000}}$ to
$\knowInv{\iota}{\exists t\ldotp \tracefrag{t} \ast \pure{|t| \le 1000} \ast
  \exists n\ldotp l_n \mapsto n \ast n = |t| }$. Concretely, this means that
instead of having a pure predicate $P$ in our robust safety theorem, we should
also allow non-pure predicates $P_{\X{np}}$ that entail $P$, i.e. $\forall t
\ldotp P_{\X{np}}(t) \wand \pure{P(t)} $, since we might have to enforce
other invariants relating to local state over the trace as well.

\begin{remark}
 I swept this under the rug in the above exposition, but if we allow boot code to run first, we have to
 make sure that the value $n$ indeed corresponds to the number of I/O events
 that have occurred when control is passed to the adversary.
\end{remark}

To make sure we can prove the driver specification, we will have to update the
robust safety theorem slightly to incorporate these changes.

Given a macro instruction to perform loops, a well/mis-behaving client might
look as follows: (TODO: write this out,
and come up with some macro formulation)

\paragraph{Never performing I/O again after some stop token has been read on $\stdin$}
Again, this requires no extra conceptual changes.

\paragraph{Verifying OCP's}
As Arma\"el noted at some point, it should be possible to simulate the
proof-style we see in OCPL by emitting values onto the trace, instead of making
assertions over them. This should give us the same proving power as the OCPL
paper, and allow us to emulate their examples.

\section{Proof sketch}
This section describes the steps involved in proving the robust safety theorem
stated above in some more detail.

\bibliographystyle{alpha}
\bibliography{biblio}

\appendix

\end{document}
